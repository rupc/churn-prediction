{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n |-- PostId: decimal(10,0) (nullable = true)\n |-- PostTypeId: decimal(10,0) (nullable = true)\n |-- AcceptedAnswerId: decimal(10,0) (nullable = true)\n |-- PostCreationDate: date (nullable = true)\n |-- Score: decimal(10,0) (nullable = true)\n |-- OwnerUserId: decimal(10,0) (nullable = true)\n |-- AnswerCount: decimal(10,0) (nullable = true)\n |-- CommentCount: decimal(10,0) (nullable = true)\n |-- ParentId: decimal(10,0) (nullable = true)\n |-- CreationDateOfOwner: date (nullable = true)\n |-- BodyWordNum: decimal(10,0) (nullable = true)\n\nroot\n |-- Id: decimal(10,0) (nullable = true)\n |-- CreationDate: date (nullable = true)\n |-- isChurn: boolean (nullable = true)\n\nroot\n |-- Id: decimal(10,0) (nullable = true)\n |-- CreationDate: date (nullable = true)\n |-- isChurn: boolean (nullable = true)\n\n+------+----------+----------------+----------------+-----+-----------+-----------+------------+--------+-------------------+-----------+\n|PostId|PostTypeId|AcceptedAnswerId|PostCreationDate|Score|OwnerUserId|AnswerCount|CommentCount|ParentId|CreationDateOfOwner|BodyWordNum|\n+------+----------+----------------+----------------+-----+-----------+-----------+------------+--------+-------------------+-----------+\n|     4|         1|               7|      2008-07-31|  630|          8|         13|           2|       0|         2008-07-31|         65|\n|     6|         1|              31|      2008-07-31|  281|          9|          6|           0|       0|         2008-07-31|         93|\n|     9|         1|            1404|      2008-07-31| 1742|          1|         63|           5|       0|         2008-07-31|         16|\n|    11|         1|            1248|      2008-07-31| 1444|          1|         37|           3|       0|         2008-07-31|         23|\n|    13|         1|               0|      2008-08-01|  590|          9|         24|          10|       0|         2008-07-31|         33|\n|    14|         1|               0|      2008-08-01|  399|         11|         10|           4|       0|         2008-08-01|         14|\n|    16|         1|           12446|      2008-08-01|  128|          2|          7|           0|       0|         2008-07-31|        145|\n|    17|         1|              26|      2008-08-01|  178|          2|          9|           3|       0|         2008-07-31|         10|\n|    19|         1|             531|      2008-08-01|  310|         13|         23|          16|       0|         2008-08-01|        415|\n|    24|         1|              49|      2008-08-01|  163|         22|          6|           0|       0|         2008-08-01|         24|\n|    25|         1|         1443907|      2008-08-01|  143|         23|          9|           0|       0|         2008-08-01|        223|\n|    36|         1|             352|      2008-08-01|  137|         32|          8|           2|       0|         2008-08-01|        220|\n|    39|         1|              45|      2008-08-01|   90|         33|          2|           0|       0|         2008-08-01|        139|\n|    42|         1|              77|      2008-08-01|  266|         37|          8|           0|       0|         2008-08-01|         46|\n|    48|         1|           31910|      2008-08-01|  250|         40|         23|           0|       0|         2008-08-01|        151|\n|    59|         1|           43110|      2008-08-01|   96|         45|          7|           0|       0|         2008-08-01|         48|\n|    66|         1|            4521|      2008-08-01|   79|         17|          4|           0|       0|         2008-08-01|         18|\n|    72|         1|               0|      2008-08-01|   41|         25|          2|           1|       0|         2008-08-01|         27|\n|    79|         1|           62853|      2008-08-01|   44|         58|          4|           0|       0|         2008-08-01|        176|\n|    80|         1|             124|      2008-08-01|   45|         26|          3|           0|       0|         2008-08-01|        188|\n+------+----------+----------------+----------------+-----+-----------+-----------+------------+--------+-------------------+-----------+\nonly showing top 20 rows\n\n+-------+------------+-------+\n|     Id|CreationDate|isChurn|\n+-------+------------+-------+\n|1083952|  2011-12-06|   true|\n| 702666|  2011-04-11|   true|\n| 898617|  2011-08-17|   true|\n|1136230|  2012-01-07|   true|\n|1033359|  2011-11-07|   true|\n| 893721|  2011-08-14|   true|\n| 458274|  2010-09-25|   true|\n| 750443|  2011-05-12|   true|\n| 628824|  2011-02-22|   true|\n| 653670|  2011-03-10|   true|\n|1056415|  2011-11-20|   true|\n| 691104|  2011-04-04|  false|\n| 527877|  2010-12-02|   true|\n|  84181|  2009-03-29|   true|\n|1014563|  2011-10-26|   true|\n|1172233|  2012-01-26|   true|\n| 689468|  2011-04-03|   true|\n| 218500|  2009-11-25|  false|\n|1116708|  2011-12-26|   true|\n| 368614|  2010-06-16|   true|\n+-------+------------+-------+\nonly showing top 20 rows\n\n+-------+------------+-------+\n|     Id|CreationDate|isChurn|\n+-------+------------+-------+\n| 976899|  2011-10-03|  false|\n|1174123|  2012-01-27|   true|\n| 791532|  2011-06-09|   true|\n| 456099|  2010-09-23|   true|\n| 996976|  2011-10-15|  false|\n| 416248|  2010-08-10|   true|\n| 175237|  2009-09-17|   true|\n| 661853|  2011-03-16|  false|\n|1007774|  2011-10-21|   true|\n|  93262|  2009-04-20|   true|\n| 548673|  2010-12-20|   true|\n| 146010|  2009-07-27|  false|\n| 275027|  2010-02-17|  false|\n|1109178|  2011-12-21|   true|\n| 180434|  2009-09-28|  false|\n| 890961|  2011-08-12|   true|\n| 963218|  2011-09-25|  false|\n| 398388|  2010-07-21|   true|\n| 104292|  2009-05-10|   true|\n|  64727|  2009-02-10|  false|\n+-------+------------+-------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.types as tp\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import when, sum, avg, col, count\n",
    "from pyspark.sql.types import LongType, IntegerType\n",
    "from pyspark.sql.functions import udf\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "spark = SparkSession.builder.appName(\"ChurnPredictions\").config(\"spark.driver.memory\", \"128g\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "post_schema = tp.StructType([\n",
    "    tp.StructField(name='PostId',                 dataType=tp.DecimalType(10),   nullable= True),\n",
    "    tp.StructField(name='PostTypeId',             dataType=tp.DecimalType(10),    nullable= True),\n",
    "    tp.StructField(name='AcceptedAnswerId',       dataType=tp.DecimalType(10),   nullable= True),\n",
    "    tp.StructField(name='CreationDate',           dataType=tp.DateType(),    nullable= True),\n",
    "    tp.StructField(name='Score',                  dataType=tp.DecimalType(10),    nullable= True),\n",
    "    tp.StructField(name='OwnerUserId',            dataType=tp.DecimalType(10),    nullable= True),\n",
    "    tp.StructField(name='AnswerCount',            dataType=tp.DecimalType(10),   nullable= True),\n",
    "    tp.StructField(name='CommentCount',           dataType=tp.DecimalType(10),   nullable= True),\n",
    "    tp.StructField(name='ParentId',               dataType=tp.DecimalType(10),   nullable= True),\n",
    "    tp.StructField(name='CreationDateOfOwner',    dataType=tp.DateType(),   nullable= True),\n",
    "    tp.StructField(name='BodyWordNum',            dataType=tp.DecimalType(10),   nullable= True),\n",
    "])\n",
    "\n",
    "users_schema = tp.StructType([\n",
    "    tp.StructField(name= 'Id',      dataType= tp.DecimalType(10),   nullable= True),\n",
    "    tp.StructField(name= 'CreationDate',  dataType= tp.DateType(),    nullable= True),\n",
    "    tp.StructField(name= 'isChurn',  dataType= tp.BooleanType(),    nullable= True),\n",
    "])\n",
    "# \"./data/posts_dist.csv\"\n",
    "# posts_dist_df = spark.read.csv(\"./data/posts_dist.csv\", header=True)\n",
    "posts_dist_df = spark.read.csv(\"./data/posts_dist.csv\", schema=post_schema, header=True)\n",
    "users_train_df = spark.read.csv(\"./data/users_train_dist.csv\", header=True, schema=users_schema)\n",
    "users_val_df = spark.read.csv(\"./data/users_val_dist.csv\", header=True, schema=users_schema)\n",
    "\n",
    "posts_dist_df = posts_dist_df.na.fill(0)\n",
    "# Rename post creation date to avoid conflicts with users table\n",
    "posts_dist_df = posts_dist_df.withColumnRenamed(\"CreationDate\", \"PostCreationDate\")\n",
    "\n",
    "posts_dist_df.printSchema()\n",
    "users_train_df.printSchema()\n",
    "users_val_df.printSchema()\n",
    "posts_dist_df.show()\n",
    "users_train_df.show()\n",
    "users_val_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------+----------+----------------+----------------+-----+-----------+------------+--------+-----------+---+------------+-------+\n",
      "| PostId|PostTypeId|AcceptedAnswerId|PostCreationDate|Score|AnswerCount|CommentCount|ParentId|BodyWordNum| Id|CreationDate|isChurn|\n",
      "+-------+----------+----------------+----------------+-----+-----------+------------+--------+-----------+---+------------+-------+\n",
      "|  11199|         1|           11215|      2008-08-14|    5|         15|           0|       0|         68|299|  2008-08-04|  false|\n",
      "|  11311|         1|           11323|      2008-08-14|   21|         12|           2|       0|         73|299|  2008-08-04|  false|\n",
      "|  28377|         1|           28452|      2008-08-26|   98|          9|           0|       0|         18|299|  2008-08-04|  false|\n",
      "|  28478|         1|           28498|      2008-08-26|   10|          2|           0|       0|         54|299|  2008-08-04|  false|\n",
      "|  50565|         1|           50590|      2008-09-08|    1|          2|           0|       0|        107|299|  2008-08-04|  false|\n",
      "|  59418|         1|           59440|      2008-09-12|    2|          1|           0|       0|         61|299|  2008-08-04|  false|\n",
      "|  59479|         1|           59488|      2008-09-12|    5|          2|           0|       0|         37|299|  2008-08-04|  false|\n",
      "|  59942|         1|               0|      2008-09-12|   14|         10|           0|       0|         49|299|  2008-08-04|  false|\n",
      "|  63291|         1|           63772|      2008-09-15|   46|         14|           0|       0|         43|299|  2008-08-04|  false|\n",
      "|  87821|         1|           87839|      2008-09-17|  185|         13|           0|       0|         33|299|  2008-08-04|  false|\n",
      "| 103688|         1|          104731|      2008-09-19|    4|          1|           0|       0|         26|299|  2008-08-04|  false|\n",
      "| 117508|         1|          117520|      2008-09-22|   13|          5|           0|       0|         15|299|  2008-08-04|  false|\n",
      "| 128277|         1|          443471|      2008-09-24|   17|         13|           0|       0|         67|299|  2008-08-04|  false|\n",
      "| 267488|         1|         1971086|      2008-11-06|  158|          6|           0|       0|         71|299|  2008-08-04|  false|\n",
      "| 425226|         1|          425245|      2009-01-08|    0|          2|           0|       0|        289|299|  2008-08-04|  false|\n",
      "| 429076|         1|          429393|      2009-01-09|    4|          2|           0|       0|        130|299|  2008-08-04|  false|\n",
      "| 429877|         1|               0|      2009-01-09|    6|         11|           0|       0|        275|299|  2008-08-04|  false|\n",
      "|2517587|         1|         2517812|      2010-03-25|    6|          2|           1|       0|        181|299|  2008-08-04|  false|\n",
      "|2518611|         1|         2519327|      2010-03-25|    1|          1|           0|       0|        194|299|  2008-08-04|  false|\n",
      "|2541267|         1|         2541367|      2010-03-29|    5|          1|           0|       0|        122|299|  2008-08-04|  false|\n",
      "+-------+----------+----------------+----------------+-----+-----------+------------+--------+-----------+---+------------+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------+----------+----------------+----------------+-----+-----------+------------+--------+-----------+-------+------------+-------+\n",
      "|PostId|PostTypeId|AcceptedAnswerId|PostCreationDate|Score|AnswerCount|CommentCount|ParentId|BodyWordNum|     Id|CreationDate|isChurn|\n",
      "+------+----------+----------------+----------------+-----+-----------+------------+--------+-----------+-------+------------+-------+\n",
      "|     6|         1|              31|      2008-07-31|  281|          6|           0|       0|         93|      9|  2008-07-31|  false|\n",
      "|    13|         1|               0|      2008-08-01|  590|         24|          10|       0|         33|      9|  2008-07-31|  false|\n",
      "|    14|         1|               0|      2008-08-01|  399|         10|           4|       0|         14|     11|  2008-08-01|   true|\n",
      "|    16|         1|           12446|      2008-08-01|  128|          7|           0|       0|        145|      2|  2008-07-31|  false|\n",
      "|    17|         1|              26|      2008-08-01|  178|          9|           3|       0|         10|      2|  2008-07-31|  false|\n",
      "|    80|         1|             124|      2008-08-01|   45|          3|           0|       0|        188|     26|  2008-08-01|  false|\n",
      "|   108|         1|             111|      2008-08-01|   44|          8|           0|       0|        199|     72|  2008-08-01|  false|\n",
      "|   145|         1|               0|      2008-08-01|   50|          9|           0|       0|         23|     87|  2008-08-01|  false|\n",
      "|   174|         1|               0|      2008-08-01|   73|          6|           2|       0|        167|     96|  2008-08-01|  false|\n",
      "|   175|         1|               0|      2008-08-01|   48|          3|           0|       0|        121|2089740|  2008-08-01|  false|\n",
      "|   180|         1|             539|      2008-08-01|   67|          8|           1|       0|         39|2089740|  2008-08-01|  false|\n",
      "|   289|         1|             298|      2008-08-02|  755|         18|           1|       0|         77|    109|  2008-08-02|  false|\n",
      "|   514|         1|             519|      2008-08-02|   20|          4|           0|       0|        131|    151|  2008-08-02|  false|\n",
      "|   650|         1|             655|      2008-08-03|  105|          7|           2|       0|        147|    143|  2008-08-02|  false|\n",
      "|   651|         1|             725|      2008-08-03|   29|          3|           0|       0|        192|    192|  2008-08-03|  false|\n",
      "|   742|         1|           33957|      2008-08-03|   51|          9|           0|       0|        112|    189|  2008-08-03|  false|\n",
      "|   746|         1|               0|      2008-08-03|   25|         18|           0|       0|         11|    192|  2008-08-03|  false|\n",
      "|   752|         1|             755|      2008-08-03|  668|         12|           0|       0|         33|    192|  2008-08-03|  false|\n",
      "|   766|         1|            1619|      2008-08-03|   35|          6|           0|       0|        101|1384652|  2008-08-01|  false|\n",
      "|   855|         1|             858|      2008-08-03|   16|          6|           0|       0|        154|     93|  2008-08-01|  false|\n",
      "+------+----------+----------------+----------------+-----+-----------+------------+--------+-----------+-------+------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DaysDiffCategorizer(DaysDiff):\n",
    "    if DaysDiff <= 30:\n",
    "        return \"early\"\n",
    "    elif DaysDiff < 210:\n",
    "        return \"mid\"\n",
    "    else:\n",
    "        return \"late\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import when, sum, avg, col, count, stddev, round\n",
    "\n",
    "def ExtractFeatures(df):\n",
    "    # 1. Calculate DaysDiff between PostCreationDate and AccountCreationDate\n",
    "    df = df.withColumn(\"DaysDiff\", F.datediff(df['PostCreationDate'], df['CreationDate']))\n",
    "    df = df.withColumn(\"DaysDiff\", df[\"DaysDiff\"].cast(IntegerType()))\n",
    "\n",
    "    df = df.filter(df.DaysDiff >= 0)\n",
    "    df = df.withColumn(\"DaysDiff\", df[\"DaysDiff\"].cast(IntegerType()))\n",
    "    df = df.withColumn(\"Id\", df[\"Id\"].cast(IntegerType()))\n",
    "\n",
    "    \n",
    "    # 2. Binning DaysDiff into Early(~30), Mid(~210), Late(210~)\n",
    "    bucket_udf = udf(DaysDiffCategorizer, StringType())\n",
    "    df = df.withColumn(\"Time\", bucket_udf(\"DaysDiff\"))\n",
    "    df = df.drop(\"DaysDiff\").drop(\"PostCreationDate\").drop(\"CreationDate\")\n",
    "    # df.show()\n",
    "\n",
    "    # 3. Extract feature: total# of question/answer posts\n",
    "    qnsPostCnt_df = df.groupBy(\"Id\",\"PostTypeId\").agg(\n",
    "        when(col(\"PostTypeId\") == \"1\", count(\"*\")).alias(\"Question\"),\n",
    "        when(col(\"PostTypeId\") == \"2\", count(\"*\")).alias(\"Answer\")\n",
    "        ).drop(\"PostTypeId\")\n",
    "    qnsPostCnt_df = qnsPostCnt_df.groupBy(\"Id\").sum()\n",
    "    qnsPostCnt_df = qnsPostCnt_df.withColumnRenamed(\"sum(Question)\", \"Questions\"). \\\n",
    "            withColumnRenamed(\"sum(Answer)\", \"Answer\").drop(\"sum(Id)\")\n",
    "\n",
    "    qnsPostCnt_df = qnsPostCnt_df.na.fill(0)\n",
    "    # dp.filter(dp.Id == 299).show()\n",
    "\n",
    "    # 4. Extract feature: total# of posts per-interval (early, mid, late)\n",
    "    time_df = df.groupBy(\"Id\", \"Time\").agg(\n",
    "        when(col(\"Time\") == \"early\", count(\"*\")).alias(\"EarlyPosts\"),\n",
    "        when(col(\"Time\") == \"mid\", count(\"*\")).alias(\"MidPost\"),\n",
    "        when(col(\"Time\") == \"late\", count(\"*\")).alias(\"LatePost\"))\n",
    "    time_df = time_df.na.fill(0)\n",
    "    time_df = time_df.groupBy(\"Id\").sum().drop(\"sum(Id)\")\n",
    "    time_df = time_df.withColumnRenamed(\"sum(EarlyPosts)\", \"Early\"). \\\n",
    "                      withColumnRenamed(\"sum(MidPost)\", \"Mid\"). \\\n",
    "                      withColumnRenamed(\"sum(LatePost)\", \"Late\")\n",
    "  \n",
    "    # 5. Extract feature: sum,avg,stddev of each score, answercount, comments, bodywordnum\n",
    "    stats_df = df.groupBy(\"Id\").agg(\n",
    "        sum(\"Score\").alias(\"sum_scr\"), \\\n",
    "        avg(\"Score\").alias(\"avg_scr\"), \\\n",
    "        round(stddev(\"Score\"), 4).alias(\"std_scr\"), \\\n",
    "        sum(\"AnswerCount\").alias(\"sum_ans\"), \\\n",
    "        avg(\"AnswerCount\").alias(\"avg_ans\"), \\\n",
    "        round(stddev(\"AnswerCount\"), 4).alias(\"std_ans\"), \\\n",
    "        sum(\"CommentCount\").alias(\"sum_cmt\"), \\\n",
    "        avg(\"CommentCount\").alias(\"avg_cmt\"), \\\n",
    "        round(stddev(\"CommentCount\"), 4).alias(\"std_cmt\"), \\\n",
    "        sum(\"BodyWordNum\").alias(\"sum_wrd\"), \\\n",
    "        avg(\"BodyWordNum\").alias(\"avg_wrd\"), \\\n",
    "        round(stddev(\"BodyWordNum\"), 4).alias(\"std_wrd\")) \\\n",
    "    .na.fill(0)\n",
    "    # .show(truncate=False)\n",
    "\n",
    "\n",
    "    \n",
    "    # 6. Extract feature: Count per-user AcceptedAnswerCount, meaning how many user's answer posts are accepted by other users\n",
    "    questionsPosts = posts_dist_df.filter(posts_dist_df.PostTypeId == 1).select('AcceptedAnswerId')\n",
    "    answersPosts = posts_dist_df.filter(posts_dist_df.PostTypeId == 2).select('PostId', 'ParentId', 'OwnerUserId').sort(\"PostId\")\n",
    "    qna = questionsPosts.join(answersPosts, questionsPosts[\"AcceptedAnswerId\"] == answersPosts[\"PostId\"], how=\"inner\").sort(\"OwnerUserId\")\n",
    "    qna = qna.withColumnRenamed(\"ParentId\", \"QuestionPostId\")\n",
    "    qna = qna.withColumnRenamed(\"OwnerUserId\", \"Id\")\n",
    "    qna = qna.drop(\"PostId\")\n",
    "    qna = qna.groupBy(\"Id\").agg(F.count(\"*\").alias(\"AcceptedAnswerCnt\"))\n",
    "    # qna.show()\n",
    "\n",
    "    churn_df = df.select(\"Id\", \"isChurn\").distinct().sort(\"Id\")\n",
    "\n",
    "    # time_df\n",
    "    # churn_df.show()\n",
    "    # df.show()    \n",
    "    # time_df.sort(\"Id\").show()\n",
    "    # qnsPostCnt_df.sort(\"Id\").show()\n",
    "    result = qnsPostCnt_df.join(time_df, \"Id\").join(stats_df, \"Id\").join(churn_df, \"Id\")\n",
    "    # result = result\n",
    "    \n",
    "    # result.show()\n",
    "    return result\n",
    "\n",
    "train_df = ExtractFeatures(train)\n",
    "train_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.repartition(1).write.format('com.databricks.spark.csv').save(\"./train.csv\",header = 'true')\n",
    "val.repartition(1).write.format('com.databricks.spark.csv').save(\"./val.csv\",header = 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import when, sum, avg, col, count\n",
    "from pyspark.sql.types import LongType, IntegerType\n",
    "from pyspark.sql.functions import udf\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "# Binning DaysDiff into Early, Mid, Late.\n",
    "def categorizer(DaysDiff):\n",
    "    if DaysDiff <= 30:\n",
    "        return \"early\"\n",
    "    elif DaysDiff < 210:\n",
    "        return \"mid\"\n",
    "    else:\n",
    "        return \"late\"\n",
    "\n",
    "def ExtractFeatures(df, dfu):\n",
    "    # Cast some numeric columns to IntegerType()\n",
    "    # df = df.withColumn(\"PostId\", df['PostId'].cast(IntegerType()))\n",
    "    # df = df.withColumn(\"AcceptedAnswerId\", df['AcceptedAnswerId'].cast(IntegerType()))\n",
    "    df = df.withColumn(\"CommentCount\", df['CommentCount'].cast(IntegerType()))\n",
    "    df = df.withColumn(\"BodyWordNum\", df['BodyWordNum'].cast(IntegerType()))\n",
    "    df = df.withColumn(\"Score\", df['Score'].cast(IntegerType()))\n",
    "    # df = df.withColumn(\"OwnerUserId\", df['OwnerUserId'].cast(IntegerType()))\n",
    "\n",
    "    # Calculate date difference between CreationDate and CreationDateOfOwner\n",
    "    df = df.withColumn(\"DaysDiff\", F.datediff(df['CreationDate'], df['CreationDateOfOwner']))\n",
    "    df = df.withColumn(\"DaysDiff\", df[\"DaysDiff\"].cast(IntegerType()))\n",
    "\n",
    "    df = df.filter(df.DaysDiff >= 0)\n",
    "    df = df.withColumn(\"DaysDiff\", df[\"DaysDiff\"].cast(IntegerType()))\n",
    "\n",
    "    df = df.select(\"Id\",\"CreationDateOfOwner\", \"PostId\", \"CreationDate\", \"DaysDiff\", \"Score\",\"AnswerCount\", \"CommentCount\", \"BodyWordNum\", \"AcceptedAnswerId\")\n",
    "    bucket_udf = udf(categorizer, StringType())\n",
    "    df = df.withColumn(\"When\", bucket_udf(\"DaysDiff\"))\n",
    "\n",
    "    dp = df.groupBy(\"Id\", \"When\").agg(when(col(\"When\") == \"early\", count(\"*\")).alias(\"EarlyPosts\"), when(col(\"When\") == \"mid\", count(\"*\")).alias(\"MidPost\"), when(col(\"When\") == \"late\", count(\"*\")).alias(\"LatePost\"))\n",
    "    dp = dp.drop(\"When\")\n",
    "    dp = dp.na.fill(0)\n",
    "    dp = dp.groupBy(\"Id\").sum()\n",
    "    # Construct per-user statistics\n",
    "    users_df = df.groupBy(\"Id\").agg(F.count(\"PostId\").alias(\"TotalPost\"), F.sum(\"Score\").alias(\"TotalScore\"), F.sum(\"AnswerCount\").alias(\"TotalAnswers\"), F.sum(\"CommentCount\").alias(\"TotalCmt\"), F.sum(\"BodyWordNum\").alias(\"TotalWords\"))\n",
    "\n",
    "    users_df = users_df.join(dfu, users_df.Id == dfu.Id)\n",
    "    users_df = users_df.drop(\"Id\")\n",
    "    users_df = users_df.drop(\"CreationDate\")\n",
    "    users_df = users_df.join(dp, ['Id'])\n",
    "    users_df = users_df.drop(\"sum(Id)\")\n",
    "    # users_df = users_df.drop(\"OwnerUserId\")\n",
    "    users_df = users_df.withColumnRenamed(\"sum(EarlyPosts)\", \"#Early\"). \\\n",
    "                                            withColumnRenamed(\"sum(MidPost)\", \"#Mid\"). \\\n",
    "                                            withColumnRenamed(\"sum(LatePost)\", \"#Late\")\n",
    "\n",
    "# users_df = users_df.select('isChurn').rdd.map(lambda x: 0 if x == \"False\" else x)\n",
    "# users_df = users_df['isChurn'].replace(True, 1, inplace=True)\n",
    "    users_df = users_df.withColumn( \"isChurn\" , F.when( F.col(\"isChurn\")==\"True\" , F.lit(1) ).otherwise(0) )\n",
    "    return users_df \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   df = posts_dist_df\n",
    "#     dfu = users_train_df\n",
    "train_df = ExtractFeatures(posts_dist_df, users_train_df)\n",
    "train_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = ExtractFeatures(posts_dist_df, users_val_dist_df)\n",
    "val_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.mllib.classification import SVMWithSGD, SVMModel\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "       inputCols=[\"TotalPost\", \"TotalScore\", \"TotalAnswers\", \"TotalCmt\", \"TotalWords\", \"#Early\", \"#Mid\", \"#Late\"],\n",
    "       outputCol=\"features\")\n",
    "\n",
    "train_df_transformed = assembler.transform(train_df)\n",
    "final_df = train_df_transformed.select(col(\"isChurn\").alias(\"label\"), col(\"features\"))\n",
    "# transformed_x.select('features').show()\n",
    "# transformed_x.show()\n",
    "# final.show()\n",
    "\n",
    "# model = SVMWithSGD.train(final, iterations=100)\n",
    "lsvc = LinearSVC(maxIter=10, regParam=0.1)\n",
    "lsvcModel = lsvc.fit(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df_transformed = assembler.transform(val_df)\n",
    "final_df = train_df_transformed.select(col(\"isChurn\").alias(\"label\"), col(\"features\"))\n",
    "lsvcModel.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct validation x,y\n",
    "val_x = users_val_dist_df.join(posts_dist_df, posts_dist_df.OwnerUserId == users_val_dist_df.Id)\n",
    "val_x.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppdf = train_df.toPandas()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}